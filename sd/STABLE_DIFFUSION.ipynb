{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ce575fa-c81d-428f-aa5f-2501ee10e1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from attention import SelfAttention, CrossAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f24bfefe-9091-48d0-8548-692cc9013465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.1+cpu'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2d6be15-e0f7-43a1-8121-f8075941b0c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 320, 64, 64])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = torch.rand((2, 320, 64, 64))  #(batch, channels, H/8, W/8)\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4192021-7e87-4268-a642-540c091a950e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 77, 768])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = torch.rand((2, 77, 768)) #(batch, seq_len, dim)\n",
    "context.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c805ac78-1e01-4161-9560-5cbfd6d769f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNET_AttentionBlock(\n",
       "  (groupnorm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "  (conv_input): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (layernorm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "  (attention_1): SelfAttention(\n",
       "    (in_proj): Linear(in_features=320, out_features=960, bias=False)\n",
       "    (out_proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "  )\n",
       "  (layernorm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "  (attention_2): CrossAttention(\n",
       "    (q_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "    (k_proj): Linear(in_features=768, out_features=320, bias=False)\n",
       "    (v_proj): Linear(in_features=768, out_features=320, bias=False)\n",
       "    (out_proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "  )\n",
       "  (layernorm_3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "  (linear_geglu_1): Linear(in_features=320, out_features=2560, bias=True)\n",
       "  (linear_geglu_2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "  (conv_output): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from diffusion import UNET_AttentionBlock\n",
    "\n",
    "attention_block = UNET_AttentionBlock(8, 40)\n",
    "attention_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04f21842-fd1e-46c3-bee2-08caac6f06f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 320, 64, 64])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_att = attention_block(z, context)\n",
    "out_att.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce8f237-aa3e-43cb-88d6-936a9c31c765",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df125198-db9e-45d4-9a14-277d240314e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNET(\n",
       "  (encoders): ModuleList(\n",
       "    (0): SwitchSequential(\n",
       "      (0): Conv2d(4, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (1-2): 2 x SwitchSequential(\n",
       "      (0): UNET_ResidualBlock(\n",
       "        (groupnorm_feature): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
       "        (conv_feature): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (linear_time): Linear(in_features=1280, out_features=320, bias=True)\n",
       "        (groupnorm_merged): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
       "        (conv_merged): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (residual_layer): Identity()\n",
       "      )\n",
       "      (1): UNET_AttentionBlock(\n",
       "        (groupnorm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "        (conv_input): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (layernorm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention_1): SelfAttention(\n",
       "          (in_proj): Linear(in_features=320, out_features=960, bias=False)\n",
       "          (out_proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "        )\n",
       "        (layernorm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention_2): CrossAttention(\n",
       "          (q_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "          (k_proj): Linear(in_features=768, out_features=320, bias=False)\n",
       "          (v_proj): Linear(in_features=768, out_features=320, bias=False)\n",
       "          (out_proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "        )\n",
       "        (layernorm_3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        (linear_geglu_1): Linear(in_features=320, out_features=2560, bias=True)\n",
       "        (linear_geglu_2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "        (conv_output): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (3): SwitchSequential(\n",
       "      (0): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    )\n",
       "    (4): SwitchSequential(\n",
       "      (0): UNET_ResidualBlock(\n",
       "        (groupnorm_feature): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
       "        (conv_feature): Conv2d(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (linear_time): Linear(in_features=1280, out_features=640, bias=True)\n",
       "        (groupnorm_merged): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "        (conv_merged): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (residual_layer): Conv2d(320, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): UNET_AttentionBlock(\n",
       "        (groupnorm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "        (conv_input): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (layernorm_1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention_1): SelfAttention(\n",
       "          (in_proj): Linear(in_features=640, out_features=1920, bias=False)\n",
       "          (out_proj): Linear(in_features=640, out_features=640, bias=True)\n",
       "        )\n",
       "        (layernorm_2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention_2): CrossAttention(\n",
       "          (q_proj): Linear(in_features=640, out_features=640, bias=False)\n",
       "          (k_proj): Linear(in_features=768, out_features=640, bias=False)\n",
       "          (v_proj): Linear(in_features=768, out_features=640, bias=False)\n",
       "          (out_proj): Linear(in_features=640, out_features=640, bias=True)\n",
       "        )\n",
       "        (layernorm_3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "        (linear_geglu_1): Linear(in_features=640, out_features=5120, bias=True)\n",
       "        (linear_geglu_2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "        (conv_output): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (5): SwitchSequential(\n",
       "      (0): UNET_ResidualBlock(\n",
       "        (groupnorm_feature): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "        (conv_feature): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (linear_time): Linear(in_features=1280, out_features=640, bias=True)\n",
       "        (groupnorm_merged): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "        (conv_merged): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (residual_layer): Identity()\n",
       "      )\n",
       "      (1): UNET_AttentionBlock(\n",
       "        (groupnorm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "        (conv_input): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (layernorm_1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention_1): SelfAttention(\n",
       "          (in_proj): Linear(in_features=640, out_features=1920, bias=False)\n",
       "          (out_proj): Linear(in_features=640, out_features=640, bias=True)\n",
       "        )\n",
       "        (layernorm_2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention_2): CrossAttention(\n",
       "          (q_proj): Linear(in_features=640, out_features=640, bias=False)\n",
       "          (k_proj): Linear(in_features=768, out_features=640, bias=False)\n",
       "          (v_proj): Linear(in_features=768, out_features=640, bias=False)\n",
       "          (out_proj): Linear(in_features=640, out_features=640, bias=True)\n",
       "        )\n",
       "        (layernorm_3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "        (linear_geglu_1): Linear(in_features=640, out_features=5120, bias=True)\n",
       "        (linear_geglu_2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "        (conv_output): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (6): SwitchSequential(\n",
       "      (0): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    )\n",
       "    (7): SwitchSequential(\n",
       "      (0): UNET_ResidualBlock(\n",
       "        (groupnorm_feature): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "        (conv_feature): Conv2d(640, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (linear_time): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (groupnorm_merged): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "        (conv_merged): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (residual_layer): Conv2d(640, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): UNET_AttentionBlock(\n",
       "        (groupnorm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "        (conv_input): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (layernorm_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention_1): SelfAttention(\n",
       "          (in_proj): Linear(in_features=1280, out_features=3840, bias=False)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (layernorm_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention_2): CrossAttention(\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (k_proj): Linear(in_features=768, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=768, out_features=1280, bias=False)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (layernorm_3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (linear_geglu_1): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "        (linear_geglu_2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (conv_output): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (8): SwitchSequential(\n",
       "      (0): UNET_ResidualBlock(\n",
       "        (groupnorm_feature): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "        (conv_feature): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (linear_time): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (groupnorm_merged): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "        (conv_merged): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (residual_layer): Identity()\n",
       "      )\n",
       "      (1): UNET_AttentionBlock(\n",
       "        (groupnorm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "        (conv_input): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (layernorm_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention_1): SelfAttention(\n",
       "          (in_proj): Linear(in_features=1280, out_features=3840, bias=False)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (layernorm_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention_2): CrossAttention(\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (k_proj): Linear(in_features=768, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=768, out_features=1280, bias=False)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (layernorm_3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (linear_geglu_1): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "        (linear_geglu_2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (conv_output): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (9): SwitchSequential(\n",
       "      (0): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    )\n",
       "    (10-11): 2 x SwitchSequential(\n",
       "      (0): UNET_ResidualBlock(\n",
       "        (groupnorm_feature): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "        (conv_feature): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (linear_time): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (groupnorm_merged): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "        (conv_merged): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (residual_layer): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (bottleneck): SwitchSequential(\n",
       "    (0): UNET_ResidualBlock(\n",
       "      (groupnorm_feature): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "      (conv_feature): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (linear_time): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      (groupnorm_merged): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "      (conv_merged): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (residual_layer): Identity()\n",
       "    )\n",
       "    (1): UNET_AttentionBlock(\n",
       "      (groupnorm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "      (conv_input): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (layernorm_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (attention_1): SelfAttention(\n",
       "        (in_proj): Linear(in_features=1280, out_features=3840, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      )\n",
       "      (layernorm_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (attention_2): CrossAttention(\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (k_proj): Linear(in_features=768, out_features=1280, bias=False)\n",
       "        (v_proj): Linear(in_features=768, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      )\n",
       "      (layernorm_3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (linear_geglu_1): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "      (linear_geglu_2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (conv_output): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (2): UNET_ResidualBlock(\n",
       "      (groupnorm_feature): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "      (conv_feature): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (linear_time): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      (groupnorm_merged): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "      (conv_merged): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (residual_layer): Identity()\n",
       "    )\n",
       "  )\n",
       "  (decoders): ModuleList(\n",
       "    (0-1): 2 x SwitchSequential(\n",
       "      (0): UNET_ResidualBlock(\n",
       "        (groupnorm_feature): GroupNorm(32, 2560, eps=1e-05, affine=True)\n",
       "        (conv_feature): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (linear_time): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (groupnorm_merged): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "        (conv_merged): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (residual_layer): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (2): SwitchSequential(\n",
       "      (0): UNET_ResidualBlock(\n",
       "        (groupnorm_feature): GroupNorm(32, 2560, eps=1e-05, affine=True)\n",
       "        (conv_feature): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (linear_time): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (groupnorm_merged): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "        (conv_merged): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (residual_layer): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): Upsample(\n",
       "        (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (3-4): 2 x SwitchSequential(\n",
       "      (0): UNET_ResidualBlock(\n",
       "        (groupnorm_feature): GroupNorm(32, 2560, eps=1e-05, affine=True)\n",
       "        (conv_feature): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (linear_time): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (groupnorm_merged): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "        (conv_merged): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (residual_layer): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): UNET_AttentionBlock(\n",
       "        (groupnorm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "        (conv_input): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (layernorm_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention_1): SelfAttention(\n",
       "          (in_proj): Linear(in_features=1280, out_features=3840, bias=False)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (layernorm_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention_2): CrossAttention(\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (k_proj): Linear(in_features=768, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=768, out_features=1280, bias=False)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (layernorm_3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (linear_geglu_1): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "        (linear_geglu_2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (conv_output): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (5): SwitchSequential(\n",
       "      (0): UNET_ResidualBlock(\n",
       "        (groupnorm_feature): GroupNorm(32, 1920, eps=1e-05, affine=True)\n",
       "        (conv_feature): Conv2d(1920, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (linear_time): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (groupnorm_merged): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "        (conv_merged): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (residual_layer): Conv2d(1920, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): UNET_AttentionBlock(\n",
       "        (groupnorm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "        (conv_input): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (layernorm_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention_1): SelfAttention(\n",
       "          (in_proj): Linear(in_features=1280, out_features=3840, bias=False)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (layernorm_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention_2): CrossAttention(\n",
       "          (q_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (k_proj): Linear(in_features=768, out_features=1280, bias=False)\n",
       "          (v_proj): Linear(in_features=768, out_features=1280, bias=False)\n",
       "          (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (layernorm_3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (linear_geglu_1): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "        (linear_geglu_2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        (conv_output): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (2): Upsample(\n",
       "        (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (6): SwitchSequential(\n",
       "      (0): UNET_ResidualBlock(\n",
       "        (groupnorm_feature): GroupNorm(32, 1920, eps=1e-05, affine=True)\n",
       "        (conv_feature): Conv2d(1920, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (linear_time): Linear(in_features=1280, out_features=640, bias=True)\n",
       "        (groupnorm_merged): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "        (conv_merged): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (residual_layer): Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): UNET_AttentionBlock(\n",
       "        (groupnorm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "        (conv_input): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (layernorm_1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention_1): SelfAttention(\n",
       "          (in_proj): Linear(in_features=640, out_features=1920, bias=False)\n",
       "          (out_proj): Linear(in_features=640, out_features=640, bias=True)\n",
       "        )\n",
       "        (layernorm_2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention_2): CrossAttention(\n",
       "          (q_proj): Linear(in_features=640, out_features=640, bias=False)\n",
       "          (k_proj): Linear(in_features=768, out_features=640, bias=False)\n",
       "          (v_proj): Linear(in_features=768, out_features=640, bias=False)\n",
       "          (out_proj): Linear(in_features=640, out_features=640, bias=True)\n",
       "        )\n",
       "        (layernorm_3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "        (linear_geglu_1): Linear(in_features=640, out_features=5120, bias=True)\n",
       "        (linear_geglu_2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "        (conv_output): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (7): SwitchSequential(\n",
       "      (0): UNET_ResidualBlock(\n",
       "        (groupnorm_feature): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "        (conv_feature): Conv2d(1280, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (linear_time): Linear(in_features=1280, out_features=640, bias=True)\n",
       "        (groupnorm_merged): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "        (conv_merged): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (residual_layer): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): UNET_AttentionBlock(\n",
       "        (groupnorm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "        (conv_input): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (layernorm_1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention_1): SelfAttention(\n",
       "          (in_proj): Linear(in_features=640, out_features=1920, bias=False)\n",
       "          (out_proj): Linear(in_features=640, out_features=640, bias=True)\n",
       "        )\n",
       "        (layernorm_2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention_2): CrossAttention(\n",
       "          (q_proj): Linear(in_features=640, out_features=640, bias=False)\n",
       "          (k_proj): Linear(in_features=768, out_features=640, bias=False)\n",
       "          (v_proj): Linear(in_features=768, out_features=640, bias=False)\n",
       "          (out_proj): Linear(in_features=640, out_features=640, bias=True)\n",
       "        )\n",
       "        (layernorm_3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "        (linear_geglu_1): Linear(in_features=640, out_features=5120, bias=True)\n",
       "        (linear_geglu_2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "        (conv_output): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (8): SwitchSequential(\n",
       "      (0): UNET_ResidualBlock(\n",
       "        (groupnorm_feature): GroupNorm(32, 960, eps=1e-05, affine=True)\n",
       "        (conv_feature): Conv2d(960, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (linear_time): Linear(in_features=1280, out_features=640, bias=True)\n",
       "        (groupnorm_merged): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "        (conv_merged): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (residual_layer): Conv2d(960, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): UNET_AttentionBlock(\n",
       "        (groupnorm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "        (conv_input): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (layernorm_1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention_1): SelfAttention(\n",
       "          (in_proj): Linear(in_features=640, out_features=1920, bias=False)\n",
       "          (out_proj): Linear(in_features=640, out_features=640, bias=True)\n",
       "        )\n",
       "        (layernorm_2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention_2): CrossAttention(\n",
       "          (q_proj): Linear(in_features=640, out_features=640, bias=False)\n",
       "          (k_proj): Linear(in_features=768, out_features=640, bias=False)\n",
       "          (v_proj): Linear(in_features=768, out_features=640, bias=False)\n",
       "          (out_proj): Linear(in_features=640, out_features=640, bias=True)\n",
       "        )\n",
       "        (layernorm_3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "        (linear_geglu_1): Linear(in_features=640, out_features=5120, bias=True)\n",
       "        (linear_geglu_2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "        (conv_output): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (2): Upsample(\n",
       "        (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (9): SwitchSequential(\n",
       "      (0): UNET_ResidualBlock(\n",
       "        (groupnorm_feature): GroupNorm(32, 960, eps=1e-05, affine=True)\n",
       "        (conv_feature): Conv2d(960, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (linear_time): Linear(in_features=1280, out_features=320, bias=True)\n",
       "        (groupnorm_merged): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
       "        (conv_merged): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (residual_layer): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): UNET_AttentionBlock(\n",
       "        (groupnorm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "        (conv_input): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (layernorm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention_1): SelfAttention(\n",
       "          (in_proj): Linear(in_features=320, out_features=960, bias=False)\n",
       "          (out_proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "        )\n",
       "        (layernorm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention_2): CrossAttention(\n",
       "          (q_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "          (k_proj): Linear(in_features=768, out_features=320, bias=False)\n",
       "          (v_proj): Linear(in_features=768, out_features=320, bias=False)\n",
       "          (out_proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "        )\n",
       "        (layernorm_3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        (linear_geglu_1): Linear(in_features=320, out_features=2560, bias=True)\n",
       "        (linear_geglu_2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "        (conv_output): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (10-11): 2 x SwitchSequential(\n",
       "      (0): UNET_ResidualBlock(\n",
       "        (groupnorm_feature): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "        (conv_feature): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (linear_time): Linear(in_features=1280, out_features=320, bias=True)\n",
       "        (groupnorm_merged): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
       "        (conv_merged): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (residual_layer): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): UNET_AttentionBlock(\n",
       "        (groupnorm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "        (conv_input): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (layernorm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention_1): SelfAttention(\n",
       "          (in_proj): Linear(in_features=320, out_features=960, bias=False)\n",
       "          (out_proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "        )\n",
       "        (layernorm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention_2): CrossAttention(\n",
       "          (q_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "          (k_proj): Linear(in_features=768, out_features=320, bias=False)\n",
       "          (v_proj): Linear(in_features=768, out_features=320, bias=False)\n",
       "          (out_proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "        )\n",
       "        (layernorm_3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "        (linear_geglu_1): Linear(in_features=320, out_features=2560, bias=True)\n",
       "        (linear_geglu_2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "        (conv_output): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from diffusion import UNET\n",
    "\n",
    "unet = UNET()\n",
    "unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e61d3f4-c184-46f9-b244-5aece0a5ebbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): SwitchSequential(\n",
       "    (0): Conv2d(4, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (1-2): 2 x SwitchSequential(\n",
       "    (0): UNET_ResidualBlock(\n",
       "      (groupnorm_feature): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
       "      (conv_feature): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (linear_time): Linear(in_features=1280, out_features=320, bias=True)\n",
       "      (groupnorm_merged): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
       "      (conv_merged): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (residual_layer): Identity()\n",
       "    )\n",
       "    (1): UNET_AttentionBlock(\n",
       "      (groupnorm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "      (conv_input): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (layernorm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "      (attention_1): SelfAttention(\n",
       "        (in_proj): Linear(in_features=320, out_features=960, bias=False)\n",
       "        (out_proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "      )\n",
       "      (layernorm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "      (attention_2): CrossAttention(\n",
       "        (q_proj): Linear(in_features=320, out_features=320, bias=False)\n",
       "        (k_proj): Linear(in_features=768, out_features=320, bias=False)\n",
       "        (v_proj): Linear(in_features=768, out_features=320, bias=False)\n",
       "        (out_proj): Linear(in_features=320, out_features=320, bias=True)\n",
       "      )\n",
       "      (layernorm_3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "      (linear_geglu_1): Linear(in_features=320, out_features=2560, bias=True)\n",
       "      (linear_geglu_2): Linear(in_features=1280, out_features=320, bias=True)\n",
       "      (conv_output): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (3): SwitchSequential(\n",
       "    (0): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  )\n",
       "  (4): SwitchSequential(\n",
       "    (0): UNET_ResidualBlock(\n",
       "      (groupnorm_feature): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
       "      (conv_feature): Conv2d(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (linear_time): Linear(in_features=1280, out_features=640, bias=True)\n",
       "      (groupnorm_merged): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "      (conv_merged): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (residual_layer): Conv2d(320, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (1): UNET_AttentionBlock(\n",
       "      (groupnorm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "      (conv_input): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (layernorm_1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "      (attention_1): SelfAttention(\n",
       "        (in_proj): Linear(in_features=640, out_features=1920, bias=False)\n",
       "        (out_proj): Linear(in_features=640, out_features=640, bias=True)\n",
       "      )\n",
       "      (layernorm_2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "      (attention_2): CrossAttention(\n",
       "        (q_proj): Linear(in_features=640, out_features=640, bias=False)\n",
       "        (k_proj): Linear(in_features=768, out_features=640, bias=False)\n",
       "        (v_proj): Linear(in_features=768, out_features=640, bias=False)\n",
       "        (out_proj): Linear(in_features=640, out_features=640, bias=True)\n",
       "      )\n",
       "      (layernorm_3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "      (linear_geglu_1): Linear(in_features=640, out_features=5120, bias=True)\n",
       "      (linear_geglu_2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "      (conv_output): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (5): SwitchSequential(\n",
       "    (0): UNET_ResidualBlock(\n",
       "      (groupnorm_feature): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "      (conv_feature): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (linear_time): Linear(in_features=1280, out_features=640, bias=True)\n",
       "      (groupnorm_merged): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "      (conv_merged): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (residual_layer): Identity()\n",
       "    )\n",
       "    (1): UNET_AttentionBlock(\n",
       "      (groupnorm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "      (conv_input): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (layernorm_1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "      (attention_1): SelfAttention(\n",
       "        (in_proj): Linear(in_features=640, out_features=1920, bias=False)\n",
       "        (out_proj): Linear(in_features=640, out_features=640, bias=True)\n",
       "      )\n",
       "      (layernorm_2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "      (attention_2): CrossAttention(\n",
       "        (q_proj): Linear(in_features=640, out_features=640, bias=False)\n",
       "        (k_proj): Linear(in_features=768, out_features=640, bias=False)\n",
       "        (v_proj): Linear(in_features=768, out_features=640, bias=False)\n",
       "        (out_proj): Linear(in_features=640, out_features=640, bias=True)\n",
       "      )\n",
       "      (layernorm_3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "      (linear_geglu_1): Linear(in_features=640, out_features=5120, bias=True)\n",
       "      (linear_geglu_2): Linear(in_features=2560, out_features=640, bias=True)\n",
       "      (conv_output): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (6): SwitchSequential(\n",
       "    (0): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  )\n",
       "  (7): SwitchSequential(\n",
       "    (0): UNET_ResidualBlock(\n",
       "      (groupnorm_feature): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "      (conv_feature): Conv2d(640, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (linear_time): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      (groupnorm_merged): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "      (conv_merged): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (residual_layer): Conv2d(640, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (1): UNET_AttentionBlock(\n",
       "      (groupnorm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "      (conv_input): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (layernorm_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (attention_1): SelfAttention(\n",
       "        (in_proj): Linear(in_features=1280, out_features=3840, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      )\n",
       "      (layernorm_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (attention_2): CrossAttention(\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (k_proj): Linear(in_features=768, out_features=1280, bias=False)\n",
       "        (v_proj): Linear(in_features=768, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      )\n",
       "      (layernorm_3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (linear_geglu_1): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "      (linear_geglu_2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (conv_output): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (8): SwitchSequential(\n",
       "    (0): UNET_ResidualBlock(\n",
       "      (groupnorm_feature): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "      (conv_feature): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (linear_time): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      (groupnorm_merged): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "      (conv_merged): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (residual_layer): Identity()\n",
       "    )\n",
       "    (1): UNET_AttentionBlock(\n",
       "      (groupnorm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "      (conv_input): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (layernorm_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (attention_1): SelfAttention(\n",
       "        (in_proj): Linear(in_features=1280, out_features=3840, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      )\n",
       "      (layernorm_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (attention_2): CrossAttention(\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "        (k_proj): Linear(in_features=768, out_features=1280, bias=False)\n",
       "        (v_proj): Linear(in_features=768, out_features=1280, bias=False)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      )\n",
       "      (layernorm_3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (linear_geglu_1): Linear(in_features=1280, out_features=10240, bias=True)\n",
       "      (linear_geglu_2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (conv_output): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (9): SwitchSequential(\n",
       "    (0): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  )\n",
       "  (10-11): 2 x SwitchSequential(\n",
       "    (0): UNET_ResidualBlock(\n",
       "      (groupnorm_feature): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "      (conv_feature): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (linear_time): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "      (groupnorm_merged): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "      (conv_merged): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (residual_layer): Identity()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unet.encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c7b05c8-0e2b-4d1a-a103-b1b12a7fe734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 64, 64])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand((2, 4, 64, 64))  #latent (z = Conv2D of x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7af3a54-8008-4a93-90e5-49e1bf89da19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 77, 768])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = torch.rand((2, 77, 768))\n",
    "context.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04b10755-c7b2-435b-a0c7-549b1f38f97d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1280])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time = torch.rand((1,1280))\n",
    "time.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2602b58d-4785-4421-8382-64c806c964a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 320, 64, 64])\n",
      "torch.Size([2, 320, 64, 64])\n",
      "torch.Size([2, 320, 64, 64])\n",
      "torch.Size([2, 320, 32, 32])\n",
      "torch.Size([2, 640, 32, 32])\n",
      "torch.Size([2, 640, 32, 32])\n",
      "torch.Size([2, 640, 16, 16])\n",
      "torch.Size([2, 1280, 16, 16])\n",
      "torch.Size([2, 1280, 16, 16])\n",
      "torch.Size([2, 1280, 8, 8])\n",
      "torch.Size([2, 1280, 8, 8])\n",
      "torch.Size([2, 1280, 8, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1280, 8, 8])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skip_connections = []\n",
    "for layers in unet.encoders:\n",
    "    x = layers(x, context, time)\n",
    "    skip_connections.append(x)\n",
    "    print(x.shape)\n",
    "\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4e84580-caf0-468f-9768-30368e4a0c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 320, 64, 64])\n",
      "torch.Size([2, 320, 64, 64])\n",
      "torch.Size([2, 320, 64, 64])\n",
      "torch.Size([2, 320, 32, 32])\n",
      "torch.Size([2, 640, 32, 32])\n",
      "torch.Size([2, 640, 32, 32])\n",
      "torch.Size([2, 640, 16, 16])\n",
      "torch.Size([2, 1280, 16, 16])\n",
      "torch.Size([2, 1280, 16, 16])\n",
      "torch.Size([2, 1280, 8, 8])\n",
      "torch.Size([2, 1280, 8, 8])\n",
      "torch.Size([2, 1280, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "for skip in skip_connections:\n",
    "    print(skip.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f710117-c43c-4944-81c4-d2a5ff7f11d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1280, 8, 8])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = unet.bottleneck(x, context, time)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09318974-43e6-472d-97b5-5510d5e05854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concat torch.Size([2, 2560, 8, 8])\n",
      "decode torch.Size([2, 1280, 8, 8])\n",
      "========================================\n",
      "concat torch.Size([2, 2560, 8, 8])\n",
      "decode torch.Size([2, 1280, 8, 8])\n",
      "========================================\n",
      "concat torch.Size([2, 2560, 8, 8])\n",
      "decode torch.Size([2, 1280, 16, 16])\n",
      "========================================\n",
      "concat torch.Size([2, 2560, 16, 16])\n",
      "decode torch.Size([2, 1280, 16, 16])\n",
      "========================================\n",
      "concat torch.Size([2, 2560, 16, 16])\n",
      "decode torch.Size([2, 1280, 16, 16])\n",
      "========================================\n",
      "concat torch.Size([2, 1920, 16, 16])\n",
      "decode torch.Size([2, 1280, 32, 32])\n",
      "========================================\n",
      "concat torch.Size([2, 1920, 32, 32])\n",
      "decode torch.Size([2, 640, 32, 32])\n",
      "========================================\n",
      "concat torch.Size([2, 1280, 32, 32])\n",
      "decode torch.Size([2, 640, 32, 32])\n",
      "========================================\n",
      "concat torch.Size([2, 960, 32, 32])\n",
      "decode torch.Size([2, 640, 64, 64])\n",
      "========================================\n",
      "concat torch.Size([2, 960, 64, 64])\n",
      "decode torch.Size([2, 320, 64, 64])\n",
      "========================================\n",
      "concat torch.Size([2, 640, 64, 64])\n",
      "decode torch.Size([2, 320, 64, 64])\n",
      "========================================\n",
      "concat torch.Size([2, 640, 64, 64])\n",
      "decode torch.Size([2, 320, 64, 64])\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "for layers in unet.decoders:\n",
    "    # Since we always concat with the skip connection of the encoder, the number of features increases before being sent to the decoder's layer\n",
    "    x = torch.cat((x, skip_connections.pop()), dim=1) \n",
    "    print(\"concat\", x.shape)\n",
    "    x = layers(x, context, time)\n",
    "    print(\"decode\", x.shape)\n",
    "    print(\"=\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d97dab47-1a8c-40c5-b1b7-58d039fd8ed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([160])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs = torch.pow(10000, -torch.arange(start=0, end=160, dtype=torch.float32) / 160) \n",
    "freqs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b37ddcf5-dd17-4727-8346-472c4e0a53e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 160])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs[None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "573485bf-bfe1-420c-a79e-11807ccf8453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestep = 980\n",
    "torch.tensor([timestep], dtype=torch.float32)[:, None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906c70ec-a69a-4046-a84d-ed032ecc886d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7126f0f0-6ba6-438a-8a85-58c683cb91ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc95d70-b672-45e6-990f-a31c2278d363",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f9f2b1d3-f98a-43a6-a7ad-49dc617248cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cherry'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fruits = ['apple', 'banana', 'cherry']\n",
    "\n",
    "fruits.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f183a624-a6ce-4dab-9437-faa1c643da5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4eaace-62cc-4fe1-839b-663138335b22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0d9f35-bde3-4179-9e86-119983cc87d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd3e125-3922-4a19-b310-f5112d6b77a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
